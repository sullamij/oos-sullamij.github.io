---
layout: post
title: "AI's Blindspots and Where to Find Them"
comments: true
description: "AI's Blindspots, FATE"
categories: [Papers/FATE]
tags:
- FATML
---
### **AI deployed in the Real-World**
AI is currently widespread in diverse areas including healthcare, crime judgement, business, education, and so forth. The confluence of AI gives the potential for the efficient social resource allocation via enhanced predictability. However, this also begets unprecedented and unexpected social and ethical issues. There are many problems in deploying AI systems and we are beginning to understand its cause and ramifications.

So, when we develop AI systems for real-world depolyment, what does it mean for them to 'work' properly? The example for AI that are deployed in our lives is not the sophiscated AI robot, but the vacumm cleansing robot. It is often dumbed down but the impact is immense. 

The current problem : `Reproducibility Crisis`, `Precision vs. Accuracy`


### **Suggested Two Frames**
- `Inside the Box` metrics 
It is the criteria that the researcher or engineers claim the model should do. e.g. the performance evaluation 
  - Accuracy 
  - Fairness 
  
 > However, the issue of only focusing in the `In-the-Box` problem is that AI is a Socio-Technical system. 
 
 It interacts with the world. Affects the environment, and the environment impacts the model.<sup>[1](#footnote_1)</sup> The AI system is more than just the technical artefact itself. When you want to evaluate a system, you need to look beyond just a technical performance. It's much more than reliability or quality assurance. There is much in environmental science where there is a chemical plant or power plant which is incredibly reliable, safe and functional but it could destroy the land of economy. It could destroy the environment in particular ways. So outside the functional elements of a product or socio-tecnhical element, there is a whole other set of things to evaluate and to think about. 
 
> For the sake of those being impacted 'now', it's worth it to think outside the box of model claims. 
 
- `Outside the Box` metrics 
  - Privacy & Consent  
  - Transparency 
    About ML <sup>[2](#footnote_2)</sup> 
  - Legal Compatibility 
  - Ethical Use Case 
  - Sustainability 
    Closing the AI Accountability Gap 

> We should start to think beyond the accuracies, beyond the metrics inside the box. 

### Related Papers 
- <a name="footnote_1">[1]</a>:Wagstaff, Kiri. "Machine learning that matters." arXiv preprint arXiv:1206.4656 (2012).[LINK](https://arxiv.org/pdf/1206.4656.pdf)
- <a name="footnote_2">[2]</a>: Raji, Inioluwa Deborah, and Jingying Yang. "ABOUT ML: Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles." arXiv preprint arXiv:1912.06166 (2019).[LINK](https://arxiv.org/pdf/1912.06166.pdf)


###### This is the review of the [Talk](https://slideslive.com/38922342/invited-talk-ais-blindspots-and-where-to-find-them) @NeurIPS 2019, Given by Deborah Raji
